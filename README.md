# Internship Task

This repository contains tasks completed as part of an internship program. Each task involves data analysis, preprocessing, and machine learning techniques. Below is a summary of the tasks:

## Task 2: Sentiment Analysis on IMDB Dataset
- **Objective**: Perform sentiment analysis on movie reviews.
- **Steps**:
  1. Load and preprocess the IMDB dataset.
  2. Use TF-IDF for feature extraction.
  3. Train a Logistic Regression model.
  4. Evaluate the model using classification metrics.

## Task 3: Credit Card Fraud Detection
- **Objective**: Detect fraudulent transactions in a credit card dataset.
- **Steps**:
  1. Load the `creditcard_reduced.csv` dataset.
  2. Handle class imbalance using SMOTE.
  3. Train a Random Forest Classifier.
  4. Evaluate the model and implement a test transaction function.

## Task 4: Placeholder Task
- **Objective**: This notebook is currently empty and serves as a placeholder for future tasks.

## Titanic Dataset Analysis
- **Objective**: Perform exploratory data analysis (EDA) on the Titanic dataset.
- **Steps**:
  1. Load and clean the dataset (handle missing values and outliers).
  2. Visualize data distributions and correlations.
  3. Analyze survival rates based on various features.

## Datasets
- `datasets/creditcard_reduced.csv`: Used for credit card fraud detection.
- `datasets/HousingData.csv`: Reserved for future tasks.

## How to Run
1. Clone the repository.
2. Install the required Python libraries.
3. Open the Jupyter Notebooks and execute the cells sequentially.

## Requirements
- Python 3.x
- Jupyter Notebook
- Libraries: pandas, numpy, matplotlib, seaborn, scikit-learn, nltk, imbalanced-learn

## Notes
- Ensure the datasets are placed in the `datasets/` folder before running the notebooks.